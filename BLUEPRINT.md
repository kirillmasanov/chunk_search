# AI Search Demo - Yandex Cloud Blueprint

## 1. Введение

**Название проекта:** AI Search Demo - Custom Chunks

**Описание задачи:**

AI Search Demo — это демонстрационное веб-приложение для показа преимуществ пользовательских чанков в Yandex Cloud AI Studio. Приложение сравнивает два подхода к чанкованию документов: автоматическое (платформа сама разбивает документ) и пользовательское (загрузка готовых чанков в формате JSONL).


**Основные сервисы Yandex Cloud:**
- Vector Store API (хранение и поиск по векторным представлениям)
- Files API (загрузка и управление файлами с поддержкой пользовательских чанков)
- AI Studio Model Gallery (генерация ответов на основе найденного контекста)

**Цель и ожидаемый результат:**

После выполнения инструкций из этого документа вы получите работающее веб-приложение, которое:
- Демонстрирует разницу между автоматическим и пользовательским чанкованием
- Показывает преимущества пользовательских чанков через сравнение score релевантности
- Предоставляет удобный веб-интерфейс для работы с обоими режимами
- Использует RAG (Retrieval-Augmented Generation) для генерации ответов

---

## 2. Архитектура решения

### Описание архитектуры

Приложение построено на основе FastAPI и работает как веб-сервис с простой архитектурой. Пользователь взаимодействует с приложением через веб-интерфейс, выбирая один из двух режимов работы:

1. **Инициализация индексов** → Создание двух Vector Store (для автоматического и пользовательского чанкования)
2. **Загрузка данных** → Загрузка файлов `faq.txt` и `faq_chunks.jsonl` в соответствующие Vector Store
3. **Индексация** → Построение векторных индексов (автоматическое чанкование для режима A, готовые чанки для режима B)
4. **Поиск** → Пользователь вводит запрос, система находит релевантные чанки в выбранном режиме
5. **Генерация ответа** → Модель генерирует ответ на основе найденных чанков
6. **Результат** → Отображение ответа и найденных чанков с их score релевантности

### Компоненты системы

```
┌─────────────────────────────────────────────────────────────┐
│                    Пользователь                              │
│                  (Web Browser)                               │
└────────────────────┬────────────────────────────────────────┘
                     │ HTTP
                     ▼
┌─────────────────────────────────────────────────────────────┐
│                   Frontend Layer                             │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  Web Interface (Vanilla JS + HTML/CSS)               │  │
│  │  - Режим A: Автоматическое чанкование                │  │
│  │  - Режим B: Пользовательские чанки                   │  │
│  │  - Поиск и отображение результатов                   │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────┬────────────────────────────────────────┘
                     │ REST API
                     ▼
┌─────────────────────────────────────────────────────────────┐
│                   Backend Layer                              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  FastAPI Application (Python)                        │  │
│  │  ┌────────────────────────────────────────────────┐  │  │
│  │  │  Vector Store Manager                          │  │  │
│  │  │  - Создание и управление Vector Store          │  │  │
│  │  │  - Загрузка файлов (txt и jsonl)               │  │  │
│  │  └────────────────────────────────────────────────┘  │  │
│  │  ┌────────────────────────────────────────────────┐  │  │
│  │  │  Search Engine                                 │  │  │
│  │  │  - Поиск по Vector Store                       │  │  │
│  │  │  - RAG генерация ответов                       │  │  │
│  │  └────────────────────────────────────────────────┘  │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────┬────────────────────────────────────────┘
                     │ OpenAI SDK
                     ▼
┌─────────────────────────────────────────────────────────────┐
│              Yandex Cloud AI Studio                          │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  Vector Store API                                    │  │
│  │  - Векторное хранилище                               │  │
│  │  - Индексация документов                             │  │
│  │  - Семантический поиск                               │  │
│  └──────────────────────────────────────────────────────┘  │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  Files API                                           │  │
│  │  - Загрузка файлов                                   │  │
│  │  - Автоматическое чанкование                         │  │
│  │  - Пользовательские чанки (JSONL)                    │  │
│  └──────────────────────────────────────────────────────┘  │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  Model Gallery                                       │  │
│  │  - qwen3-235b-a22b-fp8/latest                        │  │
│  │  - Генерация ответов на основе контекста            │  │
│  └──────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

### Используемые сервисы Yandex Cloud

| Сервис | Назначение | Необходимые роли для сервисного аккаунта |
|--------|------------|-------------------------------------------|
| **Vector Store API** | Хранение и поиск по векторным представлениям документов | - `ai.assistants.editor` — создание и управление Vector Store |
| **Files API** | Загрузка файлов с поддержкой автоматического и пользовательского чанкования | - `ai.assistants.editor` — загрузка и управление файлами |
| **AI Studio Model Gallery** | Генерация ответов на основе найденного контекста | - `ai.assistants.editor` — использование моделей для генерации ответов<br>- `ai.languageModels.user` — использование языковых моделей |


### Особенности реализации

- **Простая архитектура**: Весь код в одном файле `main.py` для простоты понимания
- **Асинхронные операции**: Использование `AsyncOpenAI` для параллельной работы с API
- **Формат JSONL**: Каждая строка — отдельный JSON объект с полем `body`
- **Настраиваемый поиск**: Параметр `max_num_results` для контроля количества результатов
- **RAG генерация**: Использование найденных чанков как контекста для модели
- **Docker-ready**: Полная поддержка контейнеризации с автоматической установкой зависимостей

---

## 3. Подготовка окружения

### Системные требования

- **Python 3.11+**
- **uv** (менеджер пакетов Python)
- **Docker и Docker Compose** (опционально, для контейнеризации)

### Установка зависимостей

#### Вариант 1: Локальная установка с uv

```bash
# Установка uv (менеджер пакетов Python)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Добавление uv в PATH
echo 'export PATH="$HOME/.cargo/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc

# Клонирование репозитория
git clone https://github.com/kirillmasanov/chunk_search
cd chunk_search

# Установка зависимостей и создание виртуального окружения
uv sync

# Активация окружения
source .venv/bin/activate  # macOS/Linux
# или
.venv\Scripts\activate     # Windows
```

**Примечание:** Команда `uv sync` автоматически:
- Создает виртуальное окружение (если его нет)
- Устанавливает все зависимости из `pyproject.toml`
- Синхронизирует окружение с lock-файлом `uv.lock`

#### Вариант 2: Docker

```bash
# Клонирование репозитория
git clone https://github.com/kirillmasanov/chunk_search
cd chunk_search

# Docker автоматически установит все зависимости при сборке
```

#### Установка Docker (Ubuntu)

Если Docker еще не установлен на вашей системе Ubuntu, выполните следующие команды:

```bash
# Обновление списка пакетов
sudo apt-get update

# Установка необходимых пакетов
sudo apt-get install -y \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# Добавление официального GPG ключа Docker
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

# Добавление репозитория Docker
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Обновление списка пакетов
sudo apt-get update

# Установка Docker Engine, containerd и Docker Compose
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# Добавление текущего пользователя в группу docker (чтобы не использовать sudo)
sudo usermod -aG docker $USER

# Применение изменений в группах (требуется перелогиниться или выполнить)
newgrp docker

# Проверка установки
docker --version
docker compose version
```

**Примечание:** После добавления пользователя в группу `docker` может потребоваться выход из системы и повторный вход для применения изменений.

### Настройка Yandex Cloud CLI (опционально)

Для автоматизации создания ресурсов установите Yandex Cloud CLI:

```bash
# Установка yc CLI
curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash

# Инициализация и конфигурация
yc init
```

---

## 4. Развёртывание инфраструктуры

### 4.1. Создание сервисного аккаунта

#### Через веб-консоль:

1. Перейдите в [консоль Yandex Cloud](https://console.cloud.yandex.ru/)
2. Выберите ваш каталог
3. Перейдите в раздел "Сервисные аккаунты"
4. Нажмите "Создать сервисный аккаунт"
5. Укажите имя, например, `ai-search-demo-sa`
6. Добавьте описание, например, "Service account for AI Search Demo"

#### Через CLI:

```bash
# Создание сервисного аккаунта
yc iam service-account create \
  --name ai-search-demo-sa \
  --description "Service account for AI Search Demo"

# Получение ID созданного аккаунта
SA_ID=$(yc iam service-account get ai-search-demo-sa --format json | jq -r '.id')
echo "Service Account ID: $SA_ID"
```

### 4.2. Назначение ролей

Сервисному аккаунту необходимы роли для работы с AI Studio:

#### Через веб-консоль:

1. Откройте страницу каталога
2. Перейдите на вкладку "Права доступа"
3. Нажмите "Назначить роли"
4. Выберите сервисный аккаунт `ai-search-demo-sa`
5. Добавьте роли:
   - `ai.assistants.editor`
   - `ai.languageModels.user`

#### Через CLI:

```bash
# Получение FOLDER_ID
FOLDER_ID=$(yc config get folder-id)

# Назначение ролей для работы с AI Studio
yc resource-manager folder add-access-binding $FOLDER_ID \
  --role ai.assistants.editor \
  --service-account-id $SA_ID

yc resource-manager folder add-access-binding $FOLDER_ID \
  --role ai.languageModels.user \
  --service-account-id $SA_ID
```

### 4.3. Создание API ключа

#### Через веб-консоль:

1. Откройте страницу сервисного аккаунта
2. Перейдите на вкладку "API-ключи"
3. Нажмите "Создать API-ключ"
4. Укажите область действия: `yc.ai.foundationModels.execute`
5. **Важно:** Скопируйте ключ (он показывается только один раз!)

#### Через CLI:

```bash
# Создание API-ключа с областью действия для Foundation Models
API_KEY=$(yc iam api-key create \
  --service-account-id $SA_ID \
  --scopes yc.ai.foundationModels.execute \
  --format json | jq -r '.secret')
echo "API Key: $API_KEY"
```

### 4.4. Настройка переменных окружения

Создайте файл `.env` в корне проекта на основе `.env.example`:

```bash
# Скопировать образец
cp .env.example .env

# Отредактировать файл и заменить значения
nano .env  # или vim .env
```

**Автоматическое создание через CLI:**

```bash
FOLDER_ID=$(yc config get folder-id)
SA_ID=$(yc iam service-account get ai-search-demo-sa --format json | jq -r '.id')
API_KEY=$(yc iam api-key create \
  --service-account-id $SA_ID \
  --scopes yc.ai.foundationModels.execute \
  --format json | jq -r '.secret')

# Создать .env в корне проекта
cat > .env << EOF
YANDEX_API_KEY=$API_KEY
YANDEX_FOLDER_ID=$FOLDER_ID
YANDEX_CLOUD_MODEL=qwen3-235b-a22b-fp8/latest
SERVER_PORT=8000
EOF

echo "Файл .env создан успешно в корне проекта"
```

**Примечание:** Файл `.env` должен находиться в корне проекта (рядом с `docker-compose.yml`), а не в директории `backend/`. Это обеспечивает единообразие для локальной разработки и Docker.

---

## 5. Запуск приложения

### Вариант 1: Запуск с использованием Python

```bash
# Из корня проекта
# Запуск приложения через uv
uv run uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

Приложение будет доступно на порту **8000**.

**Альтернативный способ (из директории backend):**

```bash
cd backend
uv run uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Вариант 2: Запуск с использованием Docker

**Важно:** Перед запуском Docker убедитесь, что вы создали `.env` файл в корне проекта (см. раздел 4.4 "Настройка переменных окружения"). Без этого файла приложение не сможет подключиться к Yandex Cloud AI Studio.

```bash
# Из корня проекта
# Создайте .env файл на основе образца
cp .env.example .env

# Отредактируйте .env и укажите ваши значения
nano .env  # или vim .env

# Убедитесь, что .env файл создан и содержит правильные значения
cat .env

# Сборка и запуск контейнера
docker compose up -d

# Просмотр логов
docker compose logs -f

# Проверка статуса
docker compose ps
```

**Перезапуск после изменений:**

Если вы внесли изменения в код или Dockerfile, перезапустите контейнер:

```bash
# Остановить контейнер
docker compose down

# Пересобрать образ без использования кэша
docker compose build --no-cache

# Запустить контейнер
docker compose up -d

# Или короткая версия (пересборка и запуск одной командой)
docker compose up -d --build --force-recreate
```

Приложение будет доступно на порту **8000** (или на порту, указанном в переменной `SERVER_PORT`).

**Примечание:** Если вы видите предупреждения о неустановленных переменных окружения (YANDEX_API_KEY, YANDEX_FOLDER_ID), это означает, что `.env` файл не создан или находится не в корне проекта, или содержит пустые значения.

### Проверка работоспособности

Откройте в браузере:
- **При локальном запуске:** `http://localhost:8000`
- **При запуске через Docker:** `http://localhost:8000`
- **При запуске на виртуальной машине:** `http://<IP-адрес-ВМ>:8000`

**Примечание:** При развертывании на виртуальной машине в Yandex Cloud убедитесь, что:
- В группе безопасности открыт соответствующий порт
- У виртуальной машины есть публичный IP-адрес (если требуется доступ из интернета)

Вы должны увидеть веб-интерфейс с:
- Кнопкой "Загрузить данные и создать индексы"
- Переключателем режимов (A и B)
- Полем для ввода поискового запроса
- Кнопкой "Найти"

---

## 6. Тестирование решения

### 6.1. Инициализация индексов

1. Откройте приложение в браузере (см. раздел "Проверка работоспособности")
2. (Опционально) Настройте "Максимальное количество результатов поиска" (по умолчанию 3)
3. Нажмите кнопку "Загрузить данные и создать индексы"
4. Дождитесь завершения процесса (1-2 минуты)
5. В терминале вы увидите логи параллельного выполнения:

```
==================================================
Инициализация AI Search Demo (параллельно)
==================================================

Запускаем 2 задач параллельно...

--------------------------------------------------
Режим A: Автоматическое чанкование
--------------------------------------------------
Загружаем файл faq.txt...

--------------------------------------------------
Режим B: Пользовательские чанки
--------------------------------------------------
Загружаем файл faq_chunks.jsonl...
Файл faq.txt загружен с ID: file_xxx
Создаем Vector Store 'FAQ Auto Chunking'...
Vector Store создан с ID: vs_xxx
Ожидаем готовности индекса 'FAQ Auto Chunking'...
Файл faq_chunks.jsonl загружен с ID: file_yyy
Создаем Vector Store 'FAQ Custom Chunks'...
Vector Store создан с ID: vs_yyy
Ожидаем готовности индекса 'FAQ Custom Chunks'...
Vector Store 'FAQ Custom Chunks' готов!
Vector Store 'FAQ Auto Chunking' готов!

==================================================
Инициализация завершена успешно!
==================================================
```

**Примечание**: Логи перемешаны, что подтверждает параллельное выполнение обеих задач.

### 6.2. Тестирование режима A (Автоматическое чанкование)

1. Выберите "Режим A" в интерфейсе
2. Введите тестовый вопрос: **"Можно ли работать без интернета?"**
3. Нажмите "Найти"
4. Изучите результаты:
   - Ответ модели
   - Найденные чанки с их score релевантности
   - Обратите внимание, что вопрос и ответ могут быть в разных чанках

### 6.3. Тестирование режима B (Пользовательские чанки)

1. Выберите "Режим B" в интерфейсе
2. Введите тот же вопрос: **"Можно ли работать без интернета?"**
3. Нажмите "Найти"
4. Сравните результаты с режимом A:
   - Score релевантности должен быть выше
   - Вопрос и ответ находятся в одном чанке
   - Ответ модели более точный и полный

### 6.4. Дополнительные тестовые вопросы

Попробуйте другие вопросы из FAQ:

1. **"Какие модели доступны в AI Studio?"**
2. **"Как создать Vector Store?"**
3. **"Что такое чанкование документов?"**
4. **"Какой формат данных для пользовательских чанков?"**

Для каждого вопроса сравните результаты между режимами A и B.

### 6.5. Тестирование через API

```bash

# Получение ID Vector Stores
curl http://localhost:8000/api/stores

# Инициализация индексов
curl -X POST http://localhost:8000/api/initialize

# Поиск в режиме A (автоматическое чанкование)
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Можно ли работать без интернета?",
    "mode": "auto",
    "max_num_results": 3
  }'

# Поиск в режиме B (пользовательские чанки) с большим количеством результатов
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Можно ли работать без интернета?",
    "mode": "chunks",
    "max_num_results": 5
  }'

# Сброс индексов
curl -X POST http://localhost:8000/api/reset

### 6.6. Проверка логов

```bash
# Для локального запуска - логи выводятся в консоль

# Для Docker
docker compose logs -f ai-search-demo
```

---

## 7. Результаты и выводы

### Ожидаемый результат

После успешного тестирования вы увидите явную разницу между двумя режимами:

**Режим A (Автоматическое чанкование):**
- Score релевантности: обычно 0.6-0.8
- Вопрос и ответ могут быть разделены
- Ответ модели может быть неполным

**Режим B (Пользовательские чанки):**
- Score релевантности: обычно 0.85-0.95
- Вопрос и ответ всегда вместе
- Ответ модели более точный и полный

### Преимущества пользовательских чанков

- **Сохранение логической целостности**: Вопрос и ответ остаются вместе
- **Более высокий score релевантности**: Улучшение на 15-30%
- **Более точные ответы модели**: Полный контекст для генерации
- **Экономия токенов**: Меньший расход токенов за счет:
  - Отсутствия дублирования контекста между чанками
  - Более точного попадания в релевантные фрагменты
  - Уменьшения количества необходимых чанков для полного ответа
- **Контроль над структурой**: Вы определяете границы чанков
- **Гибкость**: Адаптация под специфику данных

### Применение в реальных проектах

Пользовательские чанки особенно полезны для:

1. **FAQ системы**: Каждый Q&A — отдельный чанк
2. **Юридические документы**: Каждая статья — отдельный чанк
3. **Техническая документация**: Каждый раздел — отдельный чанк
4. **Код**: Каждая функция/класс — отдельный чанк
5. **Продуктовые каталоги**: Каждый товар — отдельный чанк

---

## 8. Очистка ресурсов

### Остановка приложения

**Локальный запуск:**
```bash
# Остановка приложения (Ctrl+C в терминале)
```

**Docker:**
```bash
# Остановка контейнера
docker compose down

# Полная очистка (включая volumes)
docker compose down -v
```

### Удаление Vector Stores и файлов

Через веб-интерфейс:
1. Нажмите кнопку "Удалить индексы и файлы"
2. Подтвердите действие в диалоговом окне
3. Дождитесь завершения удаления

Через API:
```bash
curl -X POST http://localhost:8000/api/reset
```

Эта операция удаляет:
- Оба Vector Store (auto и chunks)
- Все загруженные файлы из Files API

### Удаление сервисного аккаунта (опционально)

```bash
# Получение ID сервисного аккаунта
SA_ID=$(yc iam service-account get ai-search-demo-sa --format json | jq -r '.id')

# Удаление API ключей
yc iam api-key list --service-account-id $SA_ID --format json | \
  jq -r '.[].id' | \
  xargs -I {} yc iam api-key delete {}

# Удаление сервисного аккаунта
yc iam service-account delete $SA_ID
```

---

## 9. Полезные ссылки

### Документация Yandex Cloud

- [Yandex Cloud AI Studio](https://yandex.cloud/ru/docs/ai-studio/)
- [Vector Store API](https://yandex.cloud/ru/docs/ai-studio/concepts/search/vectorstore)
- [Создание агента с чанками](https://yandex.cloud/ru/docs/ai-studio/operations/agents/create-prechunked-search-agent)
- [Управление доступом в Yandex Cloud](https://cloud.yandex.ru/docs/iam/)
- [Сервисные аккаунты](https://cloud.yandex.ru/docs/iam/concepts/users/service-accounts)

### Репозиторий проекта

- [GitHub: chunk_search](https://github.com/kirillmasanov/chunk_search)

### Дополнительная документация

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Docker Documentation](https://docs.docker.com/)
- [OpenAI SDK Documentation](https://platform.openai.com/docs/api-reference)

---

## Примечания

### Ограничения

- Максимальный размер файла: зависит от лимитов Files API
- Поддерживаемые форматы: TXT для автоматического чанкования, JSONL для пользовательских чанков
- Язык: русский (можно настроить в коде)
- Модель: qwen3-235b-a22b-fp8/latest (можно изменить в `.env`)

### Рекомендации

- Используйте пользовательские чанки для структурированных данных (FAQ, документация, каталоги)
- Для неструктурированного текста автоматическое чанкование может быть достаточным
- Оптимальный размер чанка: 500-2000 токенов (~400-1500 слов)
- Для production развертывания:
  - Используйте HTTPS через reverse proxy (nginx/traefik)
  - Настройте мониторинг и логирование
  - Регулярно обновляйте зависимости
  - Рассмотрите использование постоянного хранилища для Vector Stores

### Стоимость использования

Стоимость использования зависит от:
- Количества создаваемых Vector Stores
- Объема загружаемых данных
- Количества поисковых запросов
- Использования модели для генерации ответов

Актуальные цены см. на странице тарифов [Yandex Cloud AI Studio](https://yandex.cloud/ru/docs/ai-studio/pricing).